name: ğŸ¤– Project Watch Tower AI Test Automation

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run automated tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_category:
        description: 'Test category to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - authentication
          - home
          - watch_party
          - theme
      device_type:
        description: 'Device type for testing'
        required: false
        default: 'both'
        type: choice
        options:
          - both
          - ios_simulator
          - android_emulator
      test_limit:
        description: 'Number of tests to run'
        required: false
        default: '100'
        type: string

env:
  FLUTTER_VERSION: '3.24.0'
  JAVA_VERSION: '17'
  XCODE_VERSION: '15.0'

jobs:
  # Setup and validation job
  setup:
    name: ğŸ”§ Setup & Validation
    runs-on: ubuntu-latest
    outputs:
      flutter-version: ${{ steps.flutter-setup.outputs.version }}
      test-strategy: ${{ steps.test-strategy.outputs.strategy }}
    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ğŸ” Validate Project Structure
        run: |
          echo "Validating Flutter project structure..."
          if [ ! -f "pubspec.yaml" ]; then
            echo "âŒ pubspec.yaml not found"
            exit 1
          fi
          if [ ! -d "lib" ]; then
            echo "âŒ lib directory not found"
            exit 1
          fi
          echo "âœ… Project structure validated"
          echo "ğŸ“ Project contents:"
          ls -la

      - name: ğŸ¦‹ Setup Flutter
        id: flutter-setup
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          cache: true

      - name: ğŸ” Verify Dart SDK Version
        run: |
          echo "Flutter version:"
          flutter --version
          echo "Dart SDK version:"
          dart --version
          echo "Expected Dart SDK: 3.7.0 or higher"

      - name: ğŸ“¦ Get Flutter Dependencies
        run: |
          echo "Getting Flutter dependencies..."
          flutter pub get
          if [ $? -ne 0 ]; then
            echo "âŒ Failed to get dependencies"
            echo "ğŸ“‹ Checking pubspec.yaml:"
            cat pubspec.yaml
            exit 1
          fi
          echo "âœ… Dependencies resolved successfully"

      - name: ğŸ” Flutter Doctor
        run: flutter doctor -v

      - name: ğŸ“Š Determine Test Strategy
        id: test-strategy
        run: |
          if [ "${{ github.event_name }}" == "schedule" ]; then
            echo "strategy=comprehensive" >> $GITHUB_OUTPUT
          elif [ "${{ github.event_name }}" == "pull_request" ]; then
            echo "strategy=focused" >> $GITHUB_OUTPUT
          else
            echo "strategy=standard" >> $GITHUB_OUTPUT
          fi

  # Static Analysis Job
  static-analysis:
    name: ğŸ” Static Analysis
    runs-on: ubuntu-latest
    needs: setup
    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ¦‹ Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          cache: true

      - name: ğŸ“¦ Get Dependencies
        run: flutter pub get

      - name: ğŸ” Flutter Analyze
        run: flutter analyze --fatal-infos --fatal-warnings

      - name: ğŸ“ Check Formatting
        run: dart format --set-exit-if-changed .

      - name: ğŸ›¡ï¸ Security Scan
        run: |
          echo "Running security analysis..."
          dart pub deps

  # Unit Tests Job
  unit-tests:
    name: ğŸ§ª Unit Tests
    runs-on: ubuntu-latest
    needs: [setup, static-analysis]
    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ¦‹ Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          cache: true

      - name: ğŸ“¦ Get Dependencies
        run: flutter pub get

      - name: ğŸ§ª Run Unit Tests
        run: |
          flutter test --coverage --reporter=expanded
          
      - name: ğŸ“Š Generate Coverage Report
        run: |
          dart pub global activate coverage
          dart pub global run coverage:format_coverage --lcov --in=coverage --out=coverage/lcov.info --packages=.packages --report-on=lib

      - name: ğŸ“¤ Upload Coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: coverage/lcov.info
          flags: unit-tests

  # AI Testing Job
  ai-tests:
    name: ğŸ¤– AI-Powered Tests
    runs-on: ubuntu-latest
    needs: [setup, static-analysis]
    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ¦‹ Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          cache: true

      - name: ğŸ“¦ Get Dependencies
        run: flutter pub get

      - name: ğŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Install Python Dependencies
        run: |
          pip install opencv-python numpy pillow requests

      - name: ğŸ¤– Run AI Testing System
        run: |
          echo "Running AI-powered testing system..."
          python3 enhanced_ai_tester.py --cycles 5 || echo "AI testing completed with some issues"

      - name: ğŸ“Š Generate AI Test Report
        run: |
          echo "Generating AI test report..."
          if [ -f "ai_session_report.json" ]; then
            echo "AI test report generated successfully"
            cat ai_session_report.json
          else
            echo "No AI test report found"
          fi

      - name: ğŸ“¤ Upload AI Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ai-test-results
          path: |
            ai_session_report.json
            ai_screenshots/
            *.log

  # Test Results Aggregation Job
  aggregate-results:
    name: ğŸ“Š Aggregate Test Results
    runs-on: ubuntu-latest
    needs: [unit-tests, ai-tests]
    if: always()
    steps:
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ“Š Generate Test Summary
        run: |
          echo "ğŸ“Š Test Results Summary"
          echo "======================="
          echo "Unit Tests: ${{ needs.unit-tests.result }}"
          echo "AI Tests: ${{ needs.ai-tests.result }}"
          echo "======================="
          
          # Create a simple test report
          cat << EOF > test_summary.md
          # Test Results Summary
          
          ## Unit Tests
          - Status: ${{ needs.unit-tests.result }}
          
          ## AI Tests
          - Status: ${{ needs.ai-tests.result }}
          
          ## Overall Status
          - Workflow: ${{ github.workflow }}
          - Event: ${{ github.event_name }}
          - Branch: ${{ github.ref_name }}
          - Commit: ${{ github.sha }}
          EOF

      - name: ğŸ“¤ Upload Test Summary
        uses: actions/upload-artifact@v4
        with:
          name: test-summary
          path: test_summary.md

  # Notification Job
  notify:
    name: ğŸ“¢ Notify Results
    runs-on: ubuntu-latest
    needs: [aggregate-results]
    if: always()
    steps:
      - name: ğŸ“¢ Notify Test Results
        run: |
          echo "ğŸ“¢ Test Results Notification"
          echo "============================"
          echo "Unit Tests: ${{ needs.unit-tests.result }}"
          echo "AI Tests: ${{ needs.ai-tests.result }}"
          echo "Aggregate: ${{ needs.aggregate-results.result }}"
          echo "============================"
          
          if [ "${{ needs.unit-tests.result }}" == "success" ] && [ "${{ needs.ai-tests.result }}" == "success" ]; then
            echo "âœ… All tests passed!"
          else
            echo "âŒ Some tests failed"
          fi

# Workflow completion summary
  summary:
    name: ğŸ“‹ Workflow Summary
    runs-on: ubuntu-latest
    needs: [notify]
    if: always()
    steps:
      - name: ğŸ“‹ Print Summary
        run: |
          echo "ğŸ¬ Project Watch Tower AI Test Automation Workflow Completed"
          echo "=========================================================="
          echo "Workflow: ${{ github.workflow }}"
          echo "Event: ${{ github.event_name }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Commit: ${{ github.sha }}"
          echo "Actor: ${{ github.actor }}"
          echo "Run ID: ${{ github.run_id }}"
          echo "=========================================================="
          echo "ğŸ¤– AI-powered testing completed!"